# 머신러닝 분류 모델 지표 분석 보고서

## 서론: 머신러닝 분류 모델 평가 지표의 중요성

머신러닝 모델의 개발 과정에서 학습만큼이나 중요한 단계는 모델의 성능을 정확하게 평가하는 것입니다. 학습이 완료된 모델은 실제 데이터에 얼마나 잘 일반화되어 예측을 수행하는지 검증해야 하며, 이를 위해 모델이 예측한 값과 실제 값의 일치 정도를 측정하는 **'평가 지표'**가 활용됩니다. 이 평가는 학습 과정에서 사용되지 않은 별도의 테스트 데이터셋을 통해 이루어집니다.

머신러닝의 기법, 즉 분류(Classification) 모델인지 회귀(Regression) 모델인지에 따라 적합한 평가 지표는 달라지며, 분류 모델은 이산적인 범주를 예측하는 반면, 회귀 모델은 연속적인 값을 예측합니다.

모델 평가는 단순히 최종 성능을 확인하는 것을 넘어, 모델의 생애 주기 전반에 걸쳐 이루어져야 하는 필수적인 활동입니다. 모델이 예측에서 과도하게 편향되지 않도록 하기 위해, 기업은 모델 학습부터 검증, 분석, 그리고 개선에 이르는 전체 라이프사이클에 걸쳐 모델의 동작에 대한 맥락과 가시성을 제공하는 솔루션을 필요로 합니다.

## 분류 모델 평가 지표가 필수적인 이유

분류 모델의 성능을 평가하는 것은 모델의 예측 능력을 이해하고, 강점과 약점을 정확히 파악하며, 궁극적으로 문제 해결에 가장 적합한 모델을 선택하는 데 결정적인 역할을 합니다. 다양한 머신러닝 알고리즘은 각기 다른 작업에 특화되어 있으므로, 올바른 접근 방식을 선택하기 위해서는 이러한 평가 지표에 대한 깊은 이해가 필수적입니다.

그러나 단순히 정확도가 높다고 해서 항상 좋은 모델이라고 단정할 수는 없습니다. 모델의 성능 지표는 데이터의 특성과 모델의 실제 사용 목적에 따라 신중하게 설정되어야 합니다. 예를 들어, 스팸 메일 필터링 시스템과 암 예측 모델은 실패의 비용이 다르기 때문에, 각 상황에 맞는 지표를 선택해야 합니다.

## 손실 함수와 평가 지표의 구분

머신러닝 모델의 성능을 측정하는 데 사용되는 **손실 함수(Loss Functions)**와 **평가 지표(Evaluation Metrics)**는 모두 모델 성능을 나타내지만, 그 목적과 사용 방식에는 중요한 차이가 있습니다.

### 손실 함수
- 주로 모델 학습 단계에서 사용
- 경사 하강법(Gradient Descent)과 같은 최적화 알고리즘을 통해 모델의 파라미터를 조정하는 데 활용
- 일반적으로 모델의 파라미터에 대해 미분 가능해야 효율적인 최적화가 가능

### 평가 지표
- 학습 중 및 테스트 단계에서 모델의 성능을 모니터링하고 측정하는 데 사용
- 반드시 미분 가능할 필요는 없음
- 비즈니스 목표와 진정으로 일치하는 지표를 신중하게 선택해야 함

## 분류 모델 평가의 기본 개념: 혼동 행렬

분류 모델의 성능을 평가하는 데 있어 가장 기본적이면서도 필수적인 도구는 **혼동 행렬(Confusion Matrix)**입니다. 혼동 행렬은 모델의 예측 결과와 실제 값 사이의 관계를 시각화하여 보여주는 표 형태의 요약입니다.

### 정의 및 구성 요소

혼동 행렬은 일반적으로 이진 분류(Binary Classification) 문제에서 2x2 행렬로 구성되지만, 다중 클래스 분류(Multiclass Classification) 문제에도 확장하여 적용할 수 있습니다. 

네 가지 주요 요소:

- **참 양성 (True Positive, TP)**: 모델이 양성(Positive)으로 예측했고, 실제 값도 양성인 경우
- **참 음성 (True Negative, TN)**: 모델이 음성(Negative)으로 예측했고, 실제 값도 음성인 경우
- **거짓 양성 (False Positive, FP)**: 모델이 양성으로 예측했지만, 실제 값은 음성인 경우 (Type I Error)
- **거짓 음성 (False Negative, FN)**: 모델이 음성으로 예측했지만, 실제 값은 양성인 경우 (Type II Error)

### 혼동 행렬 다이어그램

|                        | 예측: 양성 (Predicted: Positive) | 예측: 음성 (Predicted: Negative) |
|------------------------|-----------------------------------|-----------------------------------|
| **실제: 양성 (Actual: Positive)** | 참 양성 (TP)                       | 거짓 음성 (FN)                     |
| **실제: 음성 (Actual: Negative)** | 거짓 양성 (FP)                     | 참 음성 (TN)                       |

### 다른 지표의 기반으로서의 역할

혼동 행렬은 단순한 시각화 도구를 넘어, 정확도(Accuracy), 정밀도(Precision), 재현율(Recall), F1 점수(F1 Score) 등 거의 모든 핵심 분류 지표를 계산하는 데 필요한 기본 구성 요소를 제공합니다.

## 핵심 분류 모델 평가 지표

### 1. 정확도 (Accuracy)

정확도는 모델이 전체 예측 중에서 얼마나 많은 예측을 올바르게 수행했는지를 측정하는 가장 직관적인 지표입니다.

**공식:**
```
정확도 (Accuracy) = (TP + TN) / (TP + TN + FP + FN)
```

**장점:**
- 모델의 전반적인 예측 성능에 대한 포괄적인 시각 제공
- 균형 잡힌 데이터셋에서 유용
- 기술적 배경이 없는 이해관계자에게도 쉽게 설명 가능

**한계:**
- 데이터셋이 불균형할 때 매우 오해의 소지가 있음
- 특정 클래스에 대한 성능을 개별적으로 파악하기 어려움

### 2. 정밀도 (Precision)

정밀도는 모델이 양성으로 예측한 것들 중에서 실제로 양성인 비율을 측정합니다.

**공식:**
```
정밀도 (Precision) = TP / (TP + FP)
```

**해석:**
높은 정밀도 점수는 모델이 거짓 양성(FP)을 거의 만들지 않음을 의미합니다.

**사용 사례:**
- 거짓 양성(FP)의 비용이 매우 높은 경우에 중요
- 스팸 메일 필터링: 정상 메일을 스팸으로 분류하는 것을 방지
- 의료 진단: 불필요하고 값비싼 침습적 검사를 방지

### 3. 재현율 (Recall / Sensitivity)

재현율은 실제 양성인 모든 인스턴스 중에서 모델이 얼마나 많은 양성 인스턴스를 올바르게 식별했는지를 측정합니다.

**공식:**
```
재현율 (Recall) = TP / (TP + FN)
```

**해석:**
높은 재현율 점수는 모델이 거짓 음성(FN)을 거의 만들지 않음을 의미합니다.

**사용 사례:**
- 거짓 음성(FN)의 비용이 매우 높은 경우에 중요
- 암 예측: 실제 암 환자를 건강하다고 잘못 판단하는 것을 방지
- 사기 탐지: 사기 거래를 놓치는 것을 방지

### 4. F1 점수 (F1 Score)

F1 점수는 정밀도와 재현율의 조화 평균(Harmonic Mean)으로, 이 두 지표 간의 균형 잡힌 성능을 제공하는 단일 지표입니다.

**공식:**
```
F1 Score = 2 * (Precision * Recall) / (Precision + Recall)
```

**장점:**
- 정밀도와 재현율을 균형 있게 고려
- 불균형 데이터셋에서 정확도보다 선호
- 어느 한 지표에 대한 편향된 최적화를 방지

**확장:**
- **F-베타 점수(F-beta Score)**: 베타(beta) 파라미터를 사용하여 정밀도와 재현율에 다른 가중치 부여
  - F2 점수(beta=2): 재현율을 정밀도보다 두 배 중요하게 고려
  - F0.5 점수(beta=0.5): 정밀도를 더 중요하게 고려

### 5. 특이도 (Specificity)

특이도는 실제 음성인 모든 인스턴스 중에서 모델이 얼마나 많은 음성 인스턴스를 올바르게 식별했는지를 측정합니다.

**공식:**
```
특이도 (Specificity) = TN / (FP + TN)
```

**사용 사례:**
거짓 양성의 비용이 매우 높은 시나리오에서 중요 (예: 건강한 사람을 아프다고 잘못 진단하는 것을 방지)

### 6. AUC-ROC (Area Under the Receiver Operating Characteristic Curve)

ROC 곡선은 이진 분류 모델의 성능을 시각화하는 그래픽 플롯으로, 다양한 분류 임계값에 따라 참 양성률(TPR, 재현율)에 대한 거짓 양성률(FPR)의 변화를 보여줍니다.

**구성:**
- X축: 거짓 양성률(FPR = FP / (FP + TN))
- Y축: 참 양성률(TPR = TP / (TP + FN), 재현율)

**해석:**
- AUC 값이 1에 가까울수록 완벽한 모델
- 0.5는 무작위 예측과 동일한 성능

**장점:**
- 분류 임계값에 독립적인 지표
- 모델이 양성 및 음성 클래스를 얼마나 잘 구별하는지 전반적인 능력 평가

**한계:**
클래스 불균형이 심한 데이터셋에서는 덜 유용하거나 오해의 소지가 있을 수 있음

### 7. PR AUC (Area Under the Precision-Recall Curve)

정밀도-재현율 곡선은 ROC 곡선의 대안으로, 특히 클래스 불균형이 심한 데이터셋에서 분류 모델의 성능을 평가하는 데 매우 유용한 시각화 도구입니다.

**구성:**
- X축: 재현율(Recall)
- Y축: 정밀도(Precision)

**장점:**
- 불균형 데이터셋에서 특히 권장
- 주로 양성 클래스(소수 클래스)의 성능에 초점
- ROC AUC보다 더 정보적이고 덜 오해의 소지가 있는 지표 제공

### 8. 로그 손실 (Log Loss / Cross-Entropy)

로그 손실은 분류 모델의 예측 확률과 실제 레이블 간의 차이를 측정하는 지표입니다.

**공식 (이진 분류):**
```
LogLoss = -((1 – y) * log(1 – yhat) + y * log(yhat))
```

**특징:**
- 완벽한 분류기는 0.0의 로그 손실
- 종종 모델 최적화를 위한 목적 함수로 사용
- 잘못된 예측에 대해 높은 확신을 가질 때 큰 페널티 부여

### 9. 브라이어 점수 (Brier Score)

브라이어 점수는 분류 모델의 예측 확률이 실제 결과와 얼마나 잘 일치하는지, 즉 확률 보정(calibration) 정도를 측정하는 지표입니다.

**공식:**
```
BrierScore = 1/N * Sum i to N (yhat_i – y_i)^2
```

**용도:**
모델이 잘 보정된 확률을 출력하는 것이 중요할 때 사용

### 10. 코헨 카파 (Cohen Kappa Metric)

코헨 카파는 모델의 성능이 무작위 분류기보다 얼마나 더 나은지를 측정하는 통계적 척도입니다.

**특징:**
- 정확도를 불균형한 상황으로 확장
- 클래스 빈도에 기반한 무작위 예측자와 비교하여 모델의 성능 평가
- 불균형 데이터셋에서 유용

### 11. 매튜스 상관 계수 (Matthews Correlation Coefficient, MCC)

MCC는 예측된 클래스와 실제 클래스 간의 상관 관계를 측정하는 지표로, 혼동 행렬의 모든 네 가지 값(TP, TN, FP, FN)을 고려합니다.

**특징:**
- -1(완벽한 오분류)에서 +1(완벽한 분류) 사이의 값
- 0은 무작위 예측을 의미
- 불균형 문제에 특히 유용하며 해석하기 쉬움

## 불균형 데이터셋에서의 평가

실제 세계의 많은 분류 문제는 불균형 데이터셋을 가집니다. 이는 한 클래스의 샘플 수가 다른 클래스의 샘플 수보다 훨씬 많을 때 발생합니다.

### 불균형 데이터셋의 문제점

1. **다수 클래스에 대한 편향**: 알고리즘은 다수 클래스에 편향되어 예측하는 경향
2. **오해의 소지가 있는 정확도**: 정확도는 불균형 데이터셋에서 모델의 실제 성능을 오해하게 만들 수 있음
3. **소수 클래스 무시**: 모델은 소수 클래스 관측치를 노이즈로 간주하고 무시하는 경향

### 불균형 데이터셋에 적합한 지표

1. **혼동 행렬**: 모델이 각 클래스에서 어떻게 수행되는지 직접적으로 이해
2. **정밀도 및 재현율**: 양성 클래스의 성능에 초점을 맞춘 지표
3. **F1 점수 및 F-베타 점수**: 정밀도와 재현율의 균형 제공
4. **PR AUC 점수**: 주로 양성 클래스에 초점을 맞추므로 심하게 불균형한 데이터셋에서 권장
5. **코헨 카파 및 MCC**: 무작위 분류기와 비교하여 모델의 성능을 평가

### 불균형 데이터셋 처리 기법

- **재샘플링(Resampling)**: 오버샘플링, 언더샘플링
- **합성 데이터 생성**: SMOTE(Synthetic Minority Over-sampling Technique)
- **임계값 조정(Threshold Moving)**
- **특화된 알고리즘**: BalancedBaggingClassifier, 트리 기반 모델

## 평가 지표 선택 및 해석을 위한 모범 사례

### 1. 문제 및 비즈니스 맥락 이해

가장 중요한 단계는 선택하는 지표를 해결하려는 특정 비즈니스 문제 및 다양한 유형의 오류와 관련된 비용과 일치시키는 것입니다.

**예시:**
- **사기 탐지**: 사기 거래를 놓치는 것(거짓 음성)이 큰 비용 → 재현율 우선
- **스팸 필터링**: 정상 메일을 스팸으로 분류하는 것(거짓 양성)이 치명적 → 정밀도 우선
- **의료 진단**: 아픈 사람을 건강하다고 말하는 것(거짓 음성)이 심각 → 재현율(민감도) 우선

### 2. 지표 간의 상충 관계 고려

많은 지표들은 본질적인 상충 관계를 가집니다. 예를 들어, 재현율을 높이면 종종 정밀도가 감소하고 그 반대도 마찬가지입니다.

**도구:**
- **ROC 곡선**: 참 양성률(TPR)과 거짓 양성률(FPR) 사이의 상충 관계 시각화
- **정밀도-재현율 곡선**: 정밀도와 재현율을 단일 시각화로 결합

### 3. 임계값 의존성 이해 및 최적화

많은 분류 지표는 모델의 출력 확률을 클래스 예측으로 변환하기 위해 임계값이 설정되어야 합니다.

**중요 사항:**
- 최적의 임계값은 항상 0.5가 아닐 수 있음
- 특정 지표가 임계값에 따라 어떻게 변하는지 분석 필요
- 임계값 조정을 통해 선택한 지표의 성능을 크게 향상시킬 수 있음

### 4. 시각화의 중요성

평가 지표를 시각화하는 것은 모델 성능을 포괄적으로 이해하는 데 필수적입니다.

**권장 시각화:**
- **혼동 행렬 표시**: TP, TN, FP, FN의 명목 값을 직접적으로 확인
- **ROC 곡선 및 정밀도-재현율 곡선**: 다양한 임계값에 걸친 모델 성능의 포괄적인 시각
- **임계값별 지표 플롯**: 분류 임계값 변화에 따른 특정 지표의 변화 시각화

### 5. 모델 선택 및 개선

평가 지표는 머신러닝 알고리즘을 선택하고 모델을 개선하는 데 중요한 역할을 합니다. 모델 평가 과정은 일회성 이벤트가 아니라, 모델을 테스트하고, 분석하고, 개선하는 반복적인 과정입니다.

**지속적인 모니터링:**
- 데이터 유닛 테스트를 통한 데이터 형식 확인
- CI/CD 파이프라인을 통한 검증 및 제약 조건 검사
- 모델의 신뢰성 보장 및 편향 식별
- 성능의 지속적인 개선

## 결론

머신러닝 분류 모델의 평가는 모델의 신뢰성과 실제 적용 가능성을 보장하는 데 있어 핵심적인 단계입니다. 모델 평가는 단순히 학습된 모델의 성능을 측정하는 것을 넘어, 모델의 생애 주기 전반에 걸쳐 이루어져야 하는 지속적인 활동입니다.

### 핵심 요점

1. **단일 지표의 한계**: 단일 지표가 모든 상황에서 최적의 해답이 될 수 없음
2. **맥락별 지표 선택**: 비즈니스 문제의 맥락과 예측 오류의 비용에 따른 신중한 지표 선택
3. **불균형 데이터 고려**: 불균형 데이터셋에서는 소수 클래스에 초점을 맞춘 지표들이 필수적
4. **상충 관계 이해**: 정밀도와 재현율 간의 상충 관계를 이해하고 균형 지표 활용
5. **시각화의 중요성**: 혼동 행렬, ROC 곡선, 정밀도-재현율 곡선 등을 통한 포괄적 이해

궁극적으로, 효과적인 모델 평가는 기술적 깊이와 비즈니스 통찰력을 결합한 다각적인 접근 방식을 요구합니다. 이러한 접근 방식은 견고하고 신뢰할 수 있는 머신러닝 시스템을 구축하고, 실제 환경에서 그 잠재력을 최대한 발휘할 수 있도록 하는 데 기여할 것입니다.