1. Image Classification (이미지 분류)
개념 및 정의
이미지 분류는 입력 이미지를 미리 정의된 카테고리 중 하나로 분류하는 작업입니다. 전체 이미지에 대해 단일 클래스 라벨을 예측하며, 물체의 위치 정보는 제공하지 않습니다.
수학적 표현

입력: 이미지 I ∈ R^(H×W×C) (높이×너비×채널)
출력: 클래스 확률 벡터 P ∈ R^N (N개 클래스)
목표: argmax P(c|I) 찾기

주요 아키텍처 발전사
전통적 방법 (2000년대 이전)

특징 추출: SIFT, HOG, LBP 등 수작업 특징
분류기: SVM, k-NN, Decision Tree
한계: 복잡한 패턴 인식의 어려움, 수작업 특징 설계

딥러닝 혁명 (2012~)
LeNet-5 (1998)

최초의 성공적인 CNN
구조: Conv → Pool → Conv → Pool → FC
MNIST 데이터셋에서 우수한 성능

AlexNet (2012)

ImageNet 대회 우승, 딥러닝 부흥의 시작점
핵심 기법: ReLU, Dropout, Data Augmentation
GPU 활용으로 대규모 학습 가능

VGGNet (2014)

3×3 작은 필터를 깊게 쌓는 구조
VGG-16, VGG-19로 깊이의 중요성 입증
단순하고 이해하기 쉬운 구조

ResNet (2015)

Skip Connection 도입으로 gradient vanishing 해결
152층까지 깊은 네트워크 학습 가능
잔차 학습: F(x) = H(x) - x 학습

EfficientNet (2019)

Compound Scaling: 깊이, 너비, 해상도를 균형있게 확장
AutoML을 통한 최적 아키텍처 탐색
효율성과 성능의 균형

Vision Transformer (2020)

CNN 없이 순수 Transformer로 이미지 분류
패치 기반 접근: 이미지를 16×16 패치로 분할
대규모 데이터에서 CNN을 능가하는 성능

핵심 기술들
Transfer Learning
사전 훈련된 모델 → Fine-tuning → 목표 태스크

Feature Extraction: 마지막 층만 학습
Fine-tuning: 전체 네트워크를 낮은 학습률로 미세 조정
장점: 적은 데이터로도 높은 성능, 학습 시간 단축

Data Augmentation

기하학적 변환: 회전, 크기 조정, 뒤집기, 자르기
색상 변환: 밝기, 대비, 채도 조정
고급 기법: Mixup, CutMix, AutoAugment
목적: 데이터 다양성 증가, 과적합 방지

Regularization 기법

Dropout: 학습 시 일부 뉴런을 무작위로 비활성화
Batch Normalization: 배치별 정규화로 학습 안정화
Weight Decay: L2 정규화로 가중치 크기 제한

평가 지표

Accuracy: 전체 예측 중 정확한 예측 비율
Top-k Accuracy: 상위 k개 예측 중 정답이 포함된 비율
Precision/Recall: 클래스별 세밀한 성능 분석
Confusion Matrix: 클래스 간 혼동 분석


2. Object Detection (객체 탐지)
개념 및 정의
객체 탐지는 이미지 내 여러 객체의 위치(Bounding Box)와 클래스를 동시에 예측하는 작업입니다. Classification + Localization의 결합된 문제입니다.
수학적 표현

입력: 이미지 I ∈ R^(H×W×C)
출력: {(x₁, y₁, x₂, y₂, c, p)} 집합

(x₁, y₁, x₂, y₂): Bounding Box 좌표
c: 클래스 라벨
p: 확신도 점수



2-Stage Detector (높은 정확도, 느린 속도)
동작 원리

Region Proposal: 객체가 있을 만한 후보 영역 생성
Classification: 각 후보 영역을 분류 및 위치 조정

R-CNN 계열 발전사
R-CNN (2014)

Selective Search로 ~2000개 후보 영역 생성
각 영역을 CNN으로 특징 추출 → SVM으로 분류
문제점: 매우 느림 (이미지당 ~47초)

Fast R-CNN (2015)

전체 이미지에서 한 번에 특징 추출
RoI Pooling으로 고정 크기 특징 생성
개선: 속도 9배 향상, end-to-end 학습

Faster R-CNN (2015)

RPN (Region Proposal Network) 도입
Selective Search 제거, 완전한 딥러닝 파이프라인
구조: Backbone → RPN → RoI Pooling → Classification

핵심 기술: RPN (Region Proposal Network)
Anchor Box 개념:
- 미리 정의된 다양한 크기/비율의 박스
- 각 위치에서 k개의 앵커 생성
- 객체성(objectness) 점수와 박스 회귀 동시 학습
1-Stage Detector (빠른 속도, 상대적으로 낮은 정확도)
동작 원리
Region Proposal과 Classification을 하나의 네트워크에서 동시에 수행
YOLO (You Only Look Once) 계열
YOLOv1 (2016)

이미지를 S×S 그리드로 분할
각 그리드 셀이 B개의 bounding box 예측
혁신: 실시간 객체 탐지의 시작

YOLOv2/YOLO9000 (2016)

Batch Normalization, Anchor Box 도입
Multi-scale 학습, WordTree로 9000개 클래스 학습

YOLOv3 (2018)

FPN 구조로 다중 스케일 예측
3개 스케일에서 각각 3개 앵커 사용
Darknet-53 백본 네트워크

YOLOv4-v8 (2020~)

CSPNet, PANet, SAM 등 최신 기법 적용
모델 최적화와 후처리 개선
YOLOv8: 통합된 프레임워크 제공

SSD (Single Shot MultiBox Detector)

다중 스케일 특징 맵에서 예측
Default Box (Anchor) 개념
작은 객체 탐지 성능 개선

핵심 기술들
Anchor Box 시스템
python# 예시: 3개 스케일 × 3개 비율 = 9개 앵커
scales = [32, 64, 128]
ratios = [0.5, 1.0, 2.0]

다양한 크기와 비율의 객체 탐지
각 앵커에 대해 classification + regression 수행

Non-Maximum Suppression (NMS)
1. 확신도 점수로 정렬
2. 가장 높은 점수 박스 선택
3. IoU > threshold인 박스들 제거
4. 반복
Feature Pyramid Networks (FPN)

Top-down pathway로 의미 정보 전파
Lateral connection으로 위치 정보 보존
다중 스케일 객체 탐지 성능 향상

평가 지표
IoU (Intersection over Union)
IoU = (교집합 면적) / (합집합 면적)

0.5 이상이면 일반적으로 올바른 탐지로 간주

mAP (mean Average Precision)

각 클래스별 AP 계산 후 평균
mAP@0.5: IoU threshold 0.5에서의 mAP
mAP@0.5:0.95: IoU 0.5부터 0.95까지의 평균 mAP


3. Image Segmentation (이미지 분할)
개념 및 정의
이미지 분할은 이미지를 의미적으로 의미 있는 부분들로 나누는 작업으로, 픽셀 단위로 클래스를 예측합니다.
세부 분류
Semantic Segmentation (의미론적 분할)
정의: 각 픽셀을 클래스별로 분류하되, 동일 클래스의 개별 객체는 구분하지 않음
주요 모델들
FCN (Fully Convolutional Network)

완전 합성곱 네트워크로 임의 크기 이미지 처리
Skip Connection으로 세밀한 정보 보존
Upsampling으로 원본 해상도 복원

U-Net
Encoder (Contracting Path) → Decoder (Expansive Path)
     ↓                           ↑
  특징 추출                    해상도 복원
     ↓                           ↑
   Skip Connection으로 연결

의료 영상 분할에서 시작, 범용적으로 확산
대칭적인 U자 형태 구조
적은 데이터로도 우수한 성능

DeepLab 시리즈

Atrous/Dilated Convolution: 수용 영역 확장 without 해상도 손실
ASPP (Atrous Spatial Pyramid Pooling): 다중 스케일 정보 융합
CRF (Conditional Random Field): 후처리로 경계 개선

Instance Segmentation (인스턴스 분할)
정의: 동일 클래스라도 개별 객체(인스턴스)를 구분하여 분할
Mask R-CNN

Faster R-CNN 확장
RoI Align으로 정확한 위치 정보 보존
각 RoI에 대해 마스크 예측 브랜치 추가
Object Detection + Segmentation 동시 수행

YOLACT (You Only Look At CoefficienTs)

실시간 인스턴스 분할
Prototype Masks + Mask Coefficients 조합
1-stage detector 기반으로 빠른 속도

Panoptic Segmentation (전체적 분할)
정의: Semantic + Instance segmentation 통합

Stuff: 형태가 없는 배경 (하늘, 도로, 잔디)
Thing: 개별적으로 셀 수 있는 객체 (사람, 자동차)

핵심 기술들
Skip Connection의 중요성
저수준 특징 (edge, corner) + 고수준 특징 (semantic) = 정확한 분할
Dilated/Atrous Convolution
일반 3×3 Conv (rate=1):
[1][1][1]
[1][1][1]  
[1][1][1]

Dilated Conv (rate=2):
[1][ ][1][ ][1]
[ ][ ][ ][ ][ ]
[1][ ][1][ ][1]
[ ][ ][ ][ ][ ]
[1][ ][1][ ][1]

수용 영역 확장 without 파라미터 증가
해상도 유지하면서 컨텍스트 정보 획득

평가 지표
Pixel Accuracy
PA = (올바르게 분류된 픽셀 수) / (전체 픽셀 수)
IoU (Intersection over Union)
IoU_c = (클래스 c의 교집합) / (클래스 c의 합집합)
mIoU = (1/N) × Σ IoU_c
Dice Score
Dice = 2 × |A ∩ B| / (|A| + |B|)

의료 영상에서 주로 사용
IoU와 유사하지만 다른 수학적 특성


4. 최신 연구 동향 및 실습 가이드
Transformer 기반 모델들
DETR (Detection Transformer)

CNN backbone + Transformer encoder-decoder
앵커 없는 객체 탐지
Set prediction으로 중복 제거 불필요

Swin Transformer

계층적 구조의 Vision Transformer
Window 기반 attention으로 효율성 개선
다양한 비전 태스크에서 SOTA 달성

실습 환경 구축
필수 라이브러리
bash# PyTorch 환경
pip install torch torchvision
pip install opencv-python pillow
pip install albumentations  # 데이터 증강
pip install wandb  # 실험 관리

# 시각화
pip install matplotlib seaborn
주요 데이터셋

Classification: CIFAR-10/100, ImageNet
Detection: PASCAL VOC, MS COCO
Segmentation: Cityscapes, ADE20K

프로젝트 순서 권장

CIFAR-10 분류기 구현 (CNN 기초)
전이학습으로 커스텀 데이터 분류
YOLO 구현으로 객체 탐지 학습
U-Net으로 의료 영상 분할
Mask R-CNN 인스턴스 분할 실습

성능 최적화 팁
모델 경량화

Pruning: 불필요한 가중치 제거
Quantization: FP32 → INT8 변환
Knowledge Distillation: 큰 모델의 지식을 작은 모델로 전달

학습 안정화

Learning Rate Scheduling: 학습률 점진적 감소
Mixed Precision Training: FP16 + FP32 혼합 사용
Gradient Clipping: 기울기 폭발 방지